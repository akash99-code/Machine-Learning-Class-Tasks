{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d94235",
   "metadata": {},
   "source": [
    "## Review Questions-I from MDSC-301(P)\n",
    "Akash Bairagi  \n",
    "21227\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580f88e",
   "metadata": {},
   "source": [
    "Q1. Which Linear Regression training algorithm can you use if you have a training set with millions of features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecec719",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "Gradient Descent Algorithms (Batch, Mini-Batch or Stochastic).   \n",
    "We cannot use normal equations to estimate the parameters as it is computationally expensive for such high number of features.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231e0f1",
   "metadata": {},
   "source": [
    "Q2. Suppose the features in your training set have very different scales. Which algorithms might suffer from this, and how? What can you do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e11927",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "Gradient Descent Algorithms suffers as it takes lots of time before reaching the opimum.   \n",
    "We should scale our features or increase the learning rate.\n",
    "\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0acb53a",
   "metadata": {},
   "source": [
    "Q3. Suppose you use Batch Gradient Descent and you plot the validation error at every epoch. If you notice that the validation error consistently goes up, what is likely going on? How can you fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378597c6",
   "metadata": {},
   "source": [
    "Ans.\n",
    "- If Training error is going up along with Validation error, then the GD algorithm is diverging from optimum point. We should decrease the learning rate in this case.\n",
    "- If Training error is not going up, then our model is overfitting to the training dataset. We need to stop training or perform training with regularization.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e3719",
   "metadata": {},
   "source": [
    "Q4. Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad8d24",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "No.   \n",
    "It is because at a particular iteration, mini-batch GD algorthim considers a random subset of training points for parameter estimation.    We can stop the algortihm when no improvements are observed for long time.\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d505db",
   "metadata": {},
   "source": [
    "Q5. Suppose you are using Polynomial Regression. You plot the learning curves and you notice that there is a large gap between the training error and the validation error. What is happening? What are three ways to solve this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e5393",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "The model is overfitting.  \n",
    "3 Ways to prevent overfitting:-\n",
    "1. Regularize the model\n",
    "2. Reduce model's polynomial degree\n",
    "3. Early stopping of trainning\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d118873",
   "metadata": {},
   "source": [
    "Q6. Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter  or reduce it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32bac8",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "The model suffers from High Bias.   \n",
    "We should reduce the regularization hyperparameter.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94cfad",
   "metadata": {},
   "source": [
    "Q7. Why would you want to use:\n",
    "\n",
    "* Ridge Regression instead of plain Linear Regression (i.e., without any regularization)?\n",
    "* Lasso instead of Ridge Regression?\n",
    "* Elastic Net instead of Lasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864b5bb",
   "metadata": {},
   "source": [
    "Ans. \n",
    "1. Ridge Regression prevents model from overfitting the training dataset, and also matrix for ridge regression is always invertible.\n",
    "2. Lasso Regularizer can push the weights down to exactly zero, while Ridge Regression cannot. Thus, Lasso can help in good feature selection.\n",
    "3. Lasso can misbehave when training data is small or mulitcollinearity is present. Then we can use Elastic Net to get best of both Ridge and Lasso.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0eb82",
   "metadata": {},
   "source": [
    "Q8. Can you name four of the main challenges in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c58a4",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "Challenges of Machine Learning:  \n",
    "1. Insufficient quantity of taining data\n",
    "2. Non-representative Training Data\n",
    "3. Poor-Quality Data and irrelevant Features\n",
    "4. Overfitting and Under-fitting\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09857cd",
   "metadata": {},
   "source": [
    "Q9. If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafdef7",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "The model is overfitting.  \n",
    "3 possible solutions:-\n",
    "1. Regularization\n",
    "2. Early Stopping or getting more training data\n",
    "3. K-fold cross validation\n",
    "4. Dimensionality reduction\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61456286",
   "metadata": {},
   "source": [
    "Q10. What is a test set, and why would you want to use it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8496eac",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "Test set is a dataset, coming from distibution same as validation dataset, used to evaluate model's performance on unseen dataset. The performance is final, unbiased and not acted upon to further train the model.  \n",
    "\n",
    "Why to use test dataset:  \n",
    "- discourage cheating\n",
    "- spot data leakage\n",
    "- create realistic expectations\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923730a",
   "metadata": {},
   "source": [
    "Q11. What is the purpose of a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48b71e",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "Purpose of Validation set:\n",
    "* To detect when the model starts overfitting to the training set, during its training process.\n",
    "* It is used to study the Bias and Variance of the model and take decisions on tuning its hyperparameters\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f09f31",
   "metadata": {},
   "source": [
    "Q12. What are different loss functions? Exaplain their importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d666baf",
   "metadata": {},
   "source": [
    "Ans. Different Loss functions:\n",
    "1. Mean Squared Error \n",
    "    - $ MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2$\n",
    "    - Higher errors are penalized heavily than the smaller errors. Being a differential function, it is easier to calculate gradients.\n",
    "    \n",
    "  \n",
    "  \n",
    "2. Root Mean Squared Error \n",
    "    * $RMSE = \\sqrt{MSE}$\n",
    "    * Brings MSE to the same units of data under analysis.\n",
    "    \n",
    "  \n",
    "  \n",
    "3. Mean Absolute Error \n",
    "    * $MAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i-\\hat{y}_i|$\n",
    "    * preserves the same units of measurement as the data under analysis. MAE scores increases linearly with increases in errors and thus is much more interpretable than MSE.\n",
    "    \n",
    "  \n",
    "4. Hinge Loss \n",
    "    * $Hinge Loss = max(0, 1- y\\cdot\\hat{y})$\n",
    "    * It is most commonly employed to regularize soft margin support vector machines. \n",
    "    \n",
    "  \n",
    "  \n",
    "5. Logistic/Cross Entropy Loss \n",
    "    * leads to better probability estimation at the cost of accuracy.\n",
    "    * $L = -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot log(\\hat{y_i})$\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da196778",
   "metadata": {},
   "source": [
    "Q13. Explain the following:\n",
    "\n",
    "- Gradient descent\n",
    "- Mini-batch gradient descent\n",
    "- Batch gradient, and\n",
    "- Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc2eae",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "* Gradient Descent:  \n",
    "    * It is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.\n",
    "\n",
    "* Mini-Batch Gradient Descent\n",
    "    * A batch of a fixed number of training examples which is less than the actual dataset is used to calculate the gradients at every iteration of GD algorithm.\n",
    "\n",
    "* Batch gradient\n",
    "    * All the training data is taken into consideration to calculate the gradients at every iteration of GD algorithm.\n",
    "    * It Converges directly to minima.\n",
    "    * Computationaly expensive for large dataset.\n",
    "\n",
    "* Stochastic Gradient Descent\n",
    "    * One random training data point is taken into consideration to calculate the gradients at every iteration of GD algorithm.\n",
    "    * Slows down the computations.\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd6a3b",
   "metadata": {},
   "source": [
    "Q14. What is learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2694f",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "Learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627995f",
   "metadata": {},
   "source": [
    "Q15. Define the following terms. Explain their importance in the data analysis.\n",
    "\n",
    "- $R^2$\n",
    "- Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5b379",
   "metadata": {},
   "source": [
    "Ans.\n",
    "* $R^2$\n",
    "    * R-squared is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
    "    * $R^2 = 1 - \\frac{RSS}{TSS}$\n",
    "\n",
    "\n",
    "   \n",
    "* Adjusted $R^2$\n",
    "    * Adjusted R squared is calculated by dividing the residual mean square error by sample variance of the target field. The result is then subtracted from 1.\n",
    "\n",
    "    * $Adj. R^2 = 1- \\frac{RSS/(n-k)}{TSS/(n-1)}$\n",
    "    \n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf106f0",
   "metadata": {},
   "source": [
    "Q16. Explain One-Hot Encoding and Label Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db689e8",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "One-Hot Encoding : One hot encoding is a process by which a categorical variable, whose values does not have any ordinal relationship, are mapped into new binary variables for each labels it takes. One-hot encoding is the representation of categorical variables as binary vectors. \n",
    "\n",
    "Label Encoding : Label Encoding is converting labels of a categorical into numeric form. It is usually done when its values have some ordinal relationship.\n",
    "\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21175309",
   "metadata": {},
   "source": [
    "Q17. What are the assumption on Naive Bayes algorithm in classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ebf680",
   "metadata": {},
   "source": [
    "Ans.\n",
    "The Naive Bayes assumptions: \n",
    "1. The prior probabilities for each class is either uniform or empirical\n",
    "2. The likelihood probabilities are Gaussian.  \n",
    "3. All the features (or predictors) are independent.Thus p-dimensional class-conditional distributions can be factorised into a product of p univariate distributions.\n",
    "\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c425f5",
   "metadata": {},
   "source": [
    "Q18. What is the difference between classification and regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e1d56",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "* Classification is a predictive model that approximates a mapping function from input variables to identify discrete output variables, which can be labels or categories. \n",
    "* Regression algorithms predict a continuous value based on the input variables. \n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdef73",
   "metadata": {},
   "source": [
    "Q19. How to ensure that the model is not overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654bd91",
   "metadata": {},
   "source": [
    "Ans. \n",
    "Methods to prevent overfitting:   \n",
    "1. Split data into Training, Validation and Test set\n",
    "2. K fold Cross Validation\n",
    "3. Get more data or perform Data augmentation\n",
    "4. Feature selection\n",
    "5. Dimensionality reduction\n",
    "6. Regularization\n",
    "7. Early stopping\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e59e06",
   "metadata": {},
   "source": [
    "Q20. List the main advantage of Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc9468",
   "metadata": {},
   "source": [
    "Ans.\n",
    "1. It uses Bayesian technique and thus does not require much training data\n",
    "2. It's works quickly and can save a lot of time and suitable for solving multi-class prediction problems\n",
    "3. If the independence of features holds true, Navie Bayes can perform better than other models\n",
    "4. It's better suited for categorical predictors than numerical variables\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832b1c3",
   "metadata": {},
   "source": [
    "Q21. What you shoud do when your model is suffereing from:\n",
    "\n",
    "- Low bias and high variance?\n",
    "- High bias and low variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fda5f4",
   "metadata": {},
   "source": [
    "Ans.  \n",
    "1. Low Bias and High Variance\n",
    "    * Increase Regularization parameter\n",
    "    * Get more Training data points\n",
    "  \n",
    "2. High bias and low Variance\n",
    "    * Decrease Regularization parameter\n",
    "    * Train it longer\n",
    "    * Use different Optimization algorithm\n",
    "\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d85279",
   "metadata": {},
   "source": [
    "Q22. What is the 'Naive' in the Naive Bayes Classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e8481",
   "metadata": {},
   "source": [
    "Ans. It is called Naive Bayes because it assumes independence of all features and the calculations of the probabilities for each class are simplified to make their calculations tractable.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6eabf6",
   "metadata": {},
   "source": [
    "Q23. What is bias-variance tradeoff in Machine Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca46c3",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "Bias-Variance Tradeoff in ML refers to the tradeoff between model's ability to minimize bias and variance simultaneously.  \n",
    "* If the model is too simple and has very few parameters, then it’s going to have high bias and low variance. \n",
    "* If the model is too complex and has large number of parameters, then it’s going to have high variance and low bias. \n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cb2a8",
   "metadata": {},
   "source": [
    "Q24. Explain different trade-offs in Machine Learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4eee5",
   "metadata": {},
   "source": [
    "Ans. \n",
    "Different trade-offs in ML:\n",
    "1. Bias- Variance Tradeoff\n",
    "2. Interpretability Accuracy tradeoff\n",
    "    - Interpretable models tend to become simple and thus lack necessary accuracy.\n",
    "     \n",
    "     \n",
    "3. Precision Recall Tradeoff\n",
    "    - If you increase precision, it will reduce recall and vice versa.\n",
    "      \n",
    "      \n",
    "4. Fairness Privacy Tradeoff\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8f402",
   "metadata": {},
   "source": [
    "Q25. What is cross-validation and how it is useful in traing ML models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33896b",
   "metadata": {},
   "source": [
    "Ans.   \n",
    "Cross-validation is a technique for evaluating ML models, where training is done on various subsets of the available input data and evaluating them on the complementary subset of the data.   \n",
    "Cross-validation can be used to detect overfitting. It can be useful when data is too small to split into training set and test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
